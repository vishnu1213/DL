{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT1TooD2I3AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYh46mwcJDzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/Image Classification/analytics Vidya Computer Vision.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZoEFsaqJX7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "from scipy import misc\n",
        "import glob\n",
        "import matplotlib.pyplot as plt   \n",
        "import sys \n",
        "from scipy.ndimage import rotate\n",
        "#from scipy.misc import imread, imshow\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import sys\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
        "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
        "from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
        "from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
        "from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.contrib.keras import backend\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6rZGL2rHOJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path=\"/content\"\n",
        "train=pd.read_csv(path+\"/train.csv\")\n",
        "test=pd.read_csv(path+\"/test_ApKoW4T.csv\")\n",
        "\n",
        "train_size=5000\n",
        "test_size=1252"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXqg0dRXJdgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dir(directory):\n",
        "        if os.path.exists(directory):\n",
        "            shutil.rmtree(directory)\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "path_train = path+\"/train\"\n",
        "make_dir(path_train)\n",
        "path_test = path+\"/test\"\n",
        "make_dir(path_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7AgflQLHVrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_real=[]\n",
        "train_real=[]\n",
        "path_test_real = path+\"/test_real\"\n",
        "make_dir(path_test_real)\n",
        "path_train_real = path+\"/train_real\"\n",
        "make_dir(path_train_real)\n",
        "\n",
        "make_dir(path+\"/dataset\")\n",
        "make_dir(path+\"/dataset/training/1\")\n",
        "make_dir(path+\"/dataset/training/2\")\n",
        "make_dir(path+\"/dataset/training/3\")\n",
        "make_dir(path+\"/dataset/training/4\")\n",
        "make_dir(path+\"/dataset/training/5\")\n",
        "\n",
        "make_dir(path+\"/dataset/testing/1\")\n",
        "make_dir(path+\"/dataset/testing/2\")\n",
        "make_dir(path+\"/dataset/testing/3\")\n",
        "make_dir(path+\"/dataset/testing/4\")\n",
        "make_dir(path+\"/dataset/testing/5\")\n",
        "\n",
        "for i in range(0,len(test)):\n",
        "    image = cv2.imread(path+\"/images/\"+test['image'][i]) \n",
        "    test_real.append(image)\n",
        "    cv2.imwrite(os.path.join(path_test_real+\"/\"+test['image'][i]),image)\n",
        "\n",
        "\n",
        "for i in range(0,len(train)):\n",
        "    image = cv2.imread(path+\"/images/\"+train['image'][i]) \n",
        "    train_real.append(image)\n",
        "    cv2.imwrite(os.path.join(path_train_real+\"/\"+train['image'][i]),image)\n",
        "\n",
        "path1=\"/content/dataset/training/1\"        \n",
        "path2=\"/content/dataset/training/2\"\n",
        "path3=\"/content/dataset/training/3\"\n",
        "path4=\"/content/dataset/training/4\"\n",
        "path5=\"/content/dataset/training/5\"\n",
        "\n",
        "for i in range(0,5000):\n",
        "    if(train['category'][i]==1):\n",
        "        cv2.imwrite(os.path.join(path1+\"//\"+train['image'][i]),train_real[i])\n",
        "    elif(train['category'][i]==2):\n",
        "        cv2.imwrite(os.path.join(path2+\"//\"+train['image'][i]),train_real[i])    \n",
        "    elif(train['category'][i]==3):\n",
        "        cv2.imwrite(os.path.join(path3+\"//\"+train['image'][i]),train_real[i])    \n",
        "    elif(train['category'][i]==4):\n",
        "        cv2.imwrite(os.path.join(path4+\"//\"+train['image'][i]),train_real[i])    \n",
        "    else:\n",
        "        cv2.imwrite(os.path.join(path5+\"//\"+train['image'][i]),train_real[i])    \n",
        "\n",
        "\n",
        "path1=\"/content/dataset/testing/1\"        \n",
        "path2=\"/content/dataset/testing/2\"\n",
        "path3=\"/content/dataset/testing/3\"\n",
        "path4=\"/content/dataset/testing/4\"\n",
        "path5=\"/content/dataset/testing/5\"\n",
        "\n",
        "for i in range(5000,len(train_real)):\n",
        "    if(train['category'][i]==1):\n",
        "        cv2.imwrite(os.path.join(path1+\"//\"+train['image'][i]),train_real[i])\n",
        "    elif(train['category'][i]==2):\n",
        "        cv2.imwrite(os.path.join(path2+\"//\"+train['image'][i]),train_real[i])    \n",
        "    elif(train['category'][i]==3):\n",
        "        cv2.imwrite(os.path.join(path3+\"//\"+train['image'][i]),train_real[i])    \n",
        "    elif(train['category'][i]==4):\n",
        "        cv2.imwrite(os.path.join(path4+\"//\"+train['image'][i]),train_real[i])    \n",
        "    else:\n",
        "        cv2.imwrite(os.path.join(path5+\"//\"+train['image'][i]),train_real[i])    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training and Test Data Extraction Complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mrS7oOwKQRw",
        "colab_type": "code",
        "outputId": "de1c715a-8654-4ffe-81d4-5b29eeb471e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "class LossHistory(Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_id = 0\n",
        "        self.losses = ''\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses += \"Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\\n\"\\\n",
        "            .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))\n",
        "        self.epoch_id += 1\n",
        " \n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses += 'Training begins...\\n'\n",
        " \n",
        "#script_dir = os.path.dirname(__file__)\n",
        "training_set_path = os.path.join('/content/dataset/training')\n",
        "test_set_path = os.path.join('/content/dataset/testing')\n",
        " \n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        " \n",
        "# Step 1 - Convolution\n",
        "input_size = (128, 128)\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))\n",
        " \n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal\n",
        " \n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " \n",
        "#classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "#classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " \n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        " \n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units=4096, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(units=5, activation='softmax'))\n",
        " \n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "# Part 2 - Fitting the CNN to the images\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        " \n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        " \n",
        "training_set = train_datagen.flow_from_directory(training_set_path,\n",
        "                                                 target_size=input_size,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical')\n",
        " \n",
        "test_set = test_datagen.flow_from_directory(test_set_path,\n",
        "                                            target_size=input_size,\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='categorical')\n",
        " \n",
        "# Create a loss history\n",
        "history = LossHistory()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 5 classes.\n",
            "Found 1252 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJHy2xi8K5Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=8000/batch_size,\n",
        "                         epochs=50,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=2000/batch_size,\n",
        "                         workers=12,\n",
        "                         callbacks=[history],\n",
        "                        use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS-Lb9MEl7CH",
        "colab_type": "code",
        "outputId": "4e2255d8-c5db-4940-b048-1741d7eb5d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_backup_path = os.path.join('/content/gdrive/My Drive/Image Classification/model5_colab.h5')\n",
        "classifier.save(model_backup_path)\n",
        "print(\"Model saved to\", model_backup_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saved to /content/gdrive/My Drive/Image Classification/model5_colab.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIeYTZr6LApR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "images = []\n",
        "path1=\"/content/test_real\"\n",
        "for img in os.listdir(\"/content/test_real\"):\n",
        "    img = image.load_img(path1+\"/\"+img, target_size=(128, 128))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    images.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heJndM_yLJTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.vstack(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azohVsKALM-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier._make_predict_function()\n",
        "classes=classifier.predict(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFaqbwZ6LPlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=[]\n",
        "for i in range(0,len(classes)):\n",
        "    pred.append(classes[i].argmax(axis=0)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEjNrVQLSD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "z=os.listdir(\"/content/test_real\")\n",
        "data=pd.DataFrame(list(zip(z,pred)),columns=['image','category']).to_csv(\"/content/Solutioncolab_5.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMVCnezxk76I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}